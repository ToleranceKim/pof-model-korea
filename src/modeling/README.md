# 산불 예측 모델링 문서

## 모델 개요

- **목적**: 기상 데이터를 사용하여 산불 발생 가능성 예측
- **알고리즘**: XGBoost(Extreme Gradient Boosting)
- **입력 변수**: 기온(t2m), 이슬점 온도(td2m), 강수량(tp), 풍속(wind10m)

## 설치 방법

### 의존성 패키지 설치

이 프로젝트는 특정 버전의 라이브러리에 의존하고 있습니다. 다음 명령어로 필요한 패키지를 설치하세요:

```bash
pip install -r requirements.txt
```

특히, XGBoost 1.7.6 버전이 필요합니다. 이는 3.0.0 이상 버전에서 API 호환성 문제가 있기 때문입니다.

### 환경 설정

모델 실행을 위해 다음 디렉토리 구조가 필요합니다:

- `outputs/data/`: 전처리된 기상 데이터 파일 위치
- `outputs/models/`: 학습된 모델과 시각화 결과가 저장되는 위치

## 데이터 특성

### 데이터 불균형 문제

현재 데이터셋은 극심한 클래스 불균형 문제가 있습니다:

- 전체 데이터: 74,844건
- 산불 발생 데이터: 296건(0.3955%)
- 학습 데이터 불균형 비율: 약 251:1 (scale_pos_weight: 251.64)

이러한 불균형은 모델이 희소한 산불 발생 클래스를 학습하는 데 어려움을 줍니다.

### 불균형 데이터셋의 문제점

#### 불균형 데이터셋이란?

불균형 데이터셋은 한 클래스(일반적으로 "다수 클래스")의 샘플 수가 다른 클래스(일반적으로 "소수 클래스")보다 훨씬 많은 데이터셋을 말합니다. 이 프로젝트에서는 산불이 발생하지 않은 데이터(다수 클래스)가 산불이 발생한 데이터(소수 클래스)보다 약 251배 많습니다.

#### 불균형 데이터셋 탐지 방법

1. **클래스 비율 계산**: 가장 직접적인 방법으로, 각 클래스의 샘플 수를 세어 비율을 계산합니다.

   ```python
   # 예시
   class_counts = df['af_flag'].value_counts()
   imbalance_ratio = class_counts[0] / class_counts[1]  # 부정 샘플 / 긍정 샘플
   print(f"불균형 비율: {imbalance_ratio:.2f}:1")
   ```

2. **성능 지표 불일치**: 정확도(Accuracy)는 높지만 F1 점수, Precision, Recall이 낮은 경우 불균형 데이터를 의심할 수 있습니다.

3. **혼동 행렬 분석**: 다수 클래스는 잘 예측하지만 소수 클래스 예측 성능이 현저히 낮은 패턴을 보입니다.

4. **ROC-AUC vs PR-AUC**: ROC-AUC는 높지만 PR-AUC(정밀도-재현율 곡선 아래 면적)가 낮은 경우 불균형 데이터일 가능성이 높습니다.

#### Recall과 불균형 데이터셋의 관계

높은 Recall(재현율)은 불균형 데이터셋에서 다음과 같은 의미를 가집니다:

1. **정의 관점**: Recall은 실제 양성 샘플 중 모델이 양성으로 예측한 비율입니다. 즉, `Recall = TP / (TP + FN)` 입니다.

2. **불균형 데이터에서의 Recall**:

   - 높은 Recall(0.75)과 낮은 Precision(0.03)은 불균형 데이터에서 흔히 발생하는 패턴입니다.
   - 이는 모델이 많은 샘플을 양성으로 예측하여 실제 양성 샘플을 많이 포착했지만, 그 과정에서 많은
     거짓 양성(False Positive)도 생겼다는 의미입니다.
   - 즉, 모델이 "산불이 날 것"이라고 너무 자주 예측하는 경향이 있습니다.

3. **Scale_pos_weight의 영향**:

   - XGBoost에서 `scale_pos_weight=251.64`와 같이 높은 값을 설정하면 Recall이 증가하고 Precision이 감소하는 경향이 있습니다.
   - 이는 양성 클래스에 높은 가중치를 부여해 모델이 양성 샘플을 놓치지 않도록 하기 때문입니다.

4. **해석 주의점**:
   - 높은 Recall만으로는 모델의 성능이 좋다고 판단할 수 없습니다.
   - 모든 예측을 양성으로 하면 Recall은 1.0이 되지만, 이는 실용적이지 않습니다.
   - Precision과 Recall의 균형(F1 점수)을 함께 고려해야 합니다.

현재 모델의 경우, Recall 0.75는 실제 산불의 75%를 감지할 수 있다는 의미지만, Precision 0.03은 산불 경보 중 실제 산불은 3%에 불과하다는 의미입니다. 이는 전형적인 불균형 데이터셋에서의 패턴으로, 적절한 임계값 조정과 추가적인 불균형 처리 기법이 필요함을 시사합니다.

#### 주요 문제점

1. **편향된 학습**: 기계학습 알고리즘은 기본적으로 전체 정확도를 최대화하려고 합니다. 따라서 소수 클래스를 무시하고 다수 클래스만 예측해도 높은 정확도(이 경우 99.6%)를 달성할 수 있습니다.

2. **소수 클래스 패턴 감지 어려움**: 학습 데이터에서 소수 클래스 샘플이 너무 적어 해당 클래스의 특성과 패턴을 효과적으로 학습하기 어렵습니다.

3. **오해하기 쉬운 평가 지표**: 정확도(Accuracy)만으로는 모델의 실제 성능을 판단하기 어렵습니다. 예를 들어, 모든 경우를 "산불 없음"으로 예측해도 99.6%의 정확도를 보일 수 있습니다.

4. **실무적 문제**: 산불 예측과 같은 경우, 소수 클래스(산불 발생)를 정확히 예측하는 것이 매우 중요하지만, 불균형 데이터로 학습된 모델은 이를 놓치기 쉽습니다.

#### 왜 해결해야 하는가?

1. **실제 목표 달성**: 산불 예측의 진정한 목표는 "산불이 발생하지 않음"을 예측하는 것이 아니라, 발생 가능성이 있는 산불을 사전에 감지하는 것입니다.

2. **비용 측면**: 산불을 예측하지 못하는 것(거짓 음성)의 비용은 산불이 아닌 것을 산불로 잘못 예측하는 것(거짓 양성)보다 훨씬 큽니다. 산불 한 건을 감지하지 못하면 인명과 재산 피해로 이어질 수 있습니다.

3. **모델의 일반화 능력**: 균형 잡힌 학습은 모델이 다양한 상황에서 더 잘 작동하도록 합니다. 불균형 문제를 해결하지 않으면 모델이 실제 환경에서 제대로 작동하지 않을 수 있습니다.

4. **신뢰성**: 불균형 처리가 되지 않은 모델은 단순히 다수 클래스로 예측하는 경향이 있어, 실제 의사결정에 도움이 되지 않습니다.

이러한 이유로, 산불 예측과 같은 중요한 문제에서는 불균형 데이터 문제를 적절히 다루는 것이 모델의 실용성과 신뢰성을 높이는 데 필수적입니다.

### 논문의 불균형 처리 연구

ECMWF 논문에서는 다음과 같은 방법으로 클래스 불균형 문제를 다루었습니다:

1. **확률 보정(Probability Calibration)**: XGBoost의 기본 출력 확률이 실제 발생 확률과 다를 수 있으므로, Isotonic Regression을 활용하여 예측 확률을 보정했습니다.

2. **가중치 접근법(Weighted Approach)**:

   - `scale_pos_weight` 파라미터를 활용하여 양성 클래스(산불 발생)에 더 높은 가중치 부여
   - 논문에서는 불균형 비율(Neg:Pos)만큼의 가중치를 적용하여 학습 과정에서 양성 샘플이 더 중요하게 고려되도록 함

3. **평가 지표 선택**:

   - 단순 정확도(Accuracy) 대신 ROC-AUC, Precision-Recall Curve 등을 활용
   - 특히 불균형 데이터에 더 적합한 Brier Score를 주요 평가 지표로 사용

4. **샘플링 기법 실험**:

   - 오버샘플링, 언더샘플링, SMOTE 등 다양한 방법을 실험했으나, 가중치 기반 접근법이 더 효과적이었음
   - 특히 시공간적 특성을 가진 데이터에서는 인공적인 샘플 생성이 오히려 부작용을 일으킬 수 있다고 보고

5. **앙상블 기법**:
   - 다양한 임계값에서의 예측 결과를 앙상블하여 최종 예측의 안정성 향상
   - 특히 시간적 특성을 고려한 시계열 앙상블 기법 적용

이러한 방법들을 한국 모델에 적용할 경우, 현재의 극심한 불균형(251:1)을 고려할 때 가중치 접근법과 확률 보정이 가장 효과적일 것으로 예상됩니다.

## 현재 모델 성능

### 성능 지표

- **ROC AUC**: 0.9178 (높음)
- **정밀도(Precision)**: 0.03 (산불 클래스)
- **재현율(Recall)**: 0.75 (산불 클래스)
- **F1 점수**: 0.05 (산불 클래스)

### 성능 분석

- 높은 ROC AUC 점수는 모델이 두 클래스를 대체로 잘 구분한다는 것을 의미하지만, 실제 활용 측면에서는 한계가 있습니다.
- 낮은 정밀도(0.03)는 모델이 "산불이 발생한다"고 예측할 때 실제로 맞는 경우가 약 3%에 불과하다는 의미로, 오경보율이 매우 높습니다.
- 비교적 높은 재현율(0.75)은 실제 산불의 75%를 감지할 수 있다는 의미지만, 오경보가 너무 많아 실용성이 제한됩니다.
- 이러한 결과는 `scale_pos_weight` 파라미터(251.64)를 통해 희소 클래스에 높은 가중치를 부여했기 때문입니다.

### 특성 중요도

- t2m (기온): 0.3429
- td2m (이슬점 온도): 0.3443
- tp (강수량): 0.1613
- wind10m (풍속): 0.1514

이슬점 온도와 기온이 모델에서 가장 중요한 변수로 나타났습니다.

## XGBoost 버전 호환성 이슈

### 문제점

- XGBoost 3.0.0 버전에서는 이전 버전과 API 호환성 문제가 발생합니다.
- 특히 `eval_metric`, `early_stopping_rounds` 매개변수가 XGBClassifier의 `fit()` 메서드에서 직접 사용할 수 없습니다.
- `callbacks` 매개변수도 sklearn API에서 제대로 지원되지 않는 문제가 있습니다.

### 해결책

- XGBoost 1.7.6 버전으로 다운그레이드하여 기존 코드의 호환성을 유지했습니다.
- 버전 확인: `pip install xgboost==1.7.6`

## 향후 개선 방향

### 모델 성능 개선

1. **데이터 확보**: 더 많은 산불 발생 데이터 수집
2. **샘플링 기법**: SMOTE와 같은 오버샘플링 기법 적용 검토
3. **임계값 조정**: 예측 확률의 임계값을 조정하여 정밀도와 재현율의 균형 개선
4. **앙상블 기법**: 다양한 모델을 결합하여 성능 향상

### 평가 방법 개선

1. **교차 검증**: 시간 기반 교차 검증을 통한 더 견고한 평가
2. **비용 가중 평가**: 오탐지와 미탐지의 비용을 고려한 평가 지표 도입

### 실용적 배포

1. **정밀도-재현율 트레이드오프**: 운영 환경에 맞는 최적의 임계값 설정
2. **단계별 경보 시스템**: 예측 확률을 여러 단계로 나누어 경보 수준 설정

## 사용법

### 기본 모델 훈련

```bash
python run_modeling.py
```

### Optuna 하이퍼파라미터 튜닝 실행

```bash
python src/modeling/train_model_optuna.py
```

### 모델 평가

모델 평가 결과는 훈련 과정에서 출력되며, 혼동 행렬과 분류 보고서를 통해 성능을 확인할 수 있습니다.
